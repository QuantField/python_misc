{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type lssvmReg\n",
    "   \n",
    "   # parameters for RBF kernel\n",
    "   sigma :: Float64 ;\n",
    "   \n",
    "   # regularisation parameter\n",
    "   mu    :: Float64 ;   \n",
    "   \n",
    "   x     :: Array{Float64,} ; # multi dimensional array x[][]\n",
    "   y     :: Array{Float64,1}; # one dimension array y[]\n",
    "   ntp   :: Int64;\n",
    "   alpha :: Array{Float64,1};\n",
    "   bias  :: Float64;\n",
    "   \n",
    "   # parameters for Polynomial kernel\n",
    "   pol_order :: Float64;\n",
    "   pol_ofset :: Float64;\n",
    "   \n",
    "   standarized :: Bool;\n",
    "   means       :: Array{Float64,1};\n",
    "   stds        :: Array{Float64,1};\n",
    "   \n",
    "   KernelType :: String ; # \"RBF\", \"LINEAR\", \"POLYNOMIAL\" \n",
    "   \n",
    "   train          :: Function\n",
    "   evaluateKernel :: Function\n",
    "   evaluateRBF    :: Function \n",
    "   test           :: Function  \n",
    "   trainError     :: Function\n",
    "   looResiduals   :: Function\n",
    "   press          :: Function   \n",
    "   copy           :: Function  \n",
    "   looError       :: Function\n",
    "   setRBFWidth    :: Function\n",
    "   setPolyParams  :: Function \n",
    "   setKernelType  :: Function\n",
    "   setRegParam    :: Function\n",
    "   printKernelInfo:: Function\n",
    "   printInfo      :: Function \n",
    "   initialize     :: Function  \n",
    "   cvError        :: Function   \n",
    "   standarize     :: Function   \n",
    "   initialRBFWidh :: Function\n",
    "   tuneRegularisationParameter :: Function\n",
    "   optimalRegularisation :: Function\n",
    "   optimise :: Function \n",
    "   R2       :: Function   \n",
    "   RMSE     :: Function  \n",
    "   residuals :: Function   \n",
    "   \n",
    "function lssvmReg(kernel :: String = \"rbf\", mu::Float64=0.1)\n",
    "    this = new();    \n",
    "    #this.initialize();\n",
    "    A = strip(uppercase(kernel));\n",
    "    if ( A in (\"RBF\", \"LINEAR\", \"POLYNOMIAL\" ))\n",
    "         this.KernelType = A;\n",
    "    else     \n",
    "          println(\"Only RBF, LINEAR, POLYNOMIAL are allowed\");\n",
    "    end    \n",
    "     \n",
    "    this.mu         = mu;\n",
    "   \n",
    "    # \"Deep\" copy constructor\n",
    "    # must include other new fields\n",
    "    this.copy =\n",
    "    function()\n",
    "         cp       = lssvmReg(this.KernelType, this.mu);\n",
    "         cp.alpha = copy(this.alpha);\n",
    "         cp.ntp   = this.ntp;\n",
    "         cp.bias  = this.bias;\n",
    "         cp.x     = this.x;\n",
    "         cp.y     = this.y;\n",
    "         cp.sigma = this.sigma;\n",
    "         cp.mu    = this.mu\n",
    "         cp.KernelType = deepcopy(this.KernelType);\n",
    "         cp.pol_order = this.pol_order;\n",
    "         cp.pol_ofset = this.pol_ofset;\n",
    "     return cp;   \n",
    "    end\n",
    "   \n",
    "    this.initialize =\n",
    "    function()           \n",
    "         null = zeros(1);    \n",
    "         this.alpha = null ;\n",
    "         this.ntp   = 0.;\n",
    "         this.bias  = 0.;\n",
    "         this.x     = null ;\n",
    "         this.y     = null ;\n",
    "         this.sigma = 0.;\n",
    "         this.mu    = 0.;\n",
    "         this.KernelType = \"Not set\";\n",
    "         this.pol_order = 0.;\n",
    "         this.pol_ofset = 0.;    \n",
    "    end     \n",
    "   \n",
    "    this.printInfo = \n",
    "    function()\n",
    "         this.printKernelInfo();\n",
    "         println(\" Number of Training points   = \",this.ntp);\n",
    "         println(\" alpha = \",pointer(this.alpha));\n",
    "         println(\" bias  = \",this.bias);\n",
    "         println(\" x     = \",pointer(this.x));\n",
    "         println(\" y     = \",pointer(this.y));\n",
    "         println(\" Regularisation parameter    = \",this.mu);     \n",
    "    end\n",
    "      \n",
    "    this.train = \n",
    "    function(x::Array{Float64,}, y:: Array{Float64,1})\n",
    "           n = length(y);\n",
    "           this.ntp = n;\n",
    "           this.x   = x; # shallow copy\n",
    "           this.y   = y; # shallow copy\n",
    "           K = this.evaluateKernel(x,x);\n",
    "           T = [K + mu*eye(n) ones(n,1); ones(1,n+1)];\n",
    "           T[n+1,n+1] =0;\n",
    "           tar   = [y;0];\n",
    "           Sol   = T\\tar;\n",
    "           this.alpha = Sol[1:n];\n",
    "           this.bias  = Sol[n+1];\n",
    "    end \n",
    "    \n",
    "    this.evaluateRBF = \n",
    "    function(x1:: Array{Float64,},x2:: Array{Float64,}) \n",
    "          K = sum(x1.^2,2)*ones(1,size(x2,1))+ones(size(x1,1),1)*sum(x2.^2,2)'-2*x1*x2';         \n",
    "          K = exp(-K/(this.sigma^2));\n",
    "          return K';\n",
    "    end  \n",
    "    \n",
    "    this.initialRBFWidh = \n",
    "    function()\n",
    "        return norm(std(this.x,1));\n",
    "    end\n",
    "    \n",
    "\n",
    "    # usage : bestmu , bestpress = <something>.tuneRegularisationParameter()\n",
    "    this.tuneRegularisationParameter =\n",
    "    function(Mu::Array{Float64,1})       \n",
    "        y = this.y;                       \n",
    "        lambda, V = eig(this.evaluateKernel(this.x,this.x));\n",
    "        Vt_y   = V'*y;\n",
    "        Vt_sqr = V'.^2;\n",
    "        xi     = sum(V,1)';        \n",
    "        xi2    = xi.^2;\n",
    "        PRESS = zeros(size(Mu));\n",
    "        for i in 1:length(Mu)        \n",
    "            u     = xi./(lambda+Mu[i]);\n",
    "            g     = lambda./(lambda+Mu[i]);\n",
    "            sm    = -sum(xi2./(lambda+Mu[i]));                        \n",
    "            theta = Vt_y./(lambda+Mu[i])-(-sum(u.*Vt_y)/sm)*u;                                    \n",
    "               h     = Vt_sqr'*g + (V*(u.*lambda)-1).*(V*u)/sm;                    \n",
    "            f     = V*(lambda.*theta) + -sum(u.*Vt_y)/sm;\n",
    "            loo_resid = (y - f)./(1-h);             \n",
    "            PRESS[i] = sum(loo_resid.^2);    \n",
    "            @printf(\"Mu = %4.6f  PRESS = %f\\n\", Mu[i], PRESS[i]);            \n",
    "        end\n",
    "        return PRESS;\n",
    "    end             \n",
    "\n",
    "    # find best regularistaion parameter and retrain.\n",
    "    this.optimalRegularisation =\n",
    "    function(Mu::Array{Float64,1})                \n",
    "        PRESS    = this.tuneRegularisationParameter(Mu);\n",
    "        optIndex = find(x->x==minimum(PRESS), PRESS);\n",
    "        MuBest   =  norm(Mu[optIndex]); # norm to convert form array to float\n",
    "        PrBest   = norm(PRESS[optIndex]); \n",
    "        this.setRegParam(MuBest);\n",
    "        this.train(this.x, this.y);\n",
    "        println(\"Optimised.\");\n",
    "    end\n",
    "    \n",
    "    # applies only to RBF\n",
    "    this.optimise =\n",
    "    function()\n",
    "        _lsvm = lssvmReg(\"rbf\",.1);\n",
    "        Sig = this.initialRBFWidh()*10.^[-2:.05:2]; \n",
    "        Params = zeros(length(Sig),2);\n",
    "        Mu = 10.^[-3:.1:2];\n",
    "        PRESS = zeros(size(Mu));\n",
    "        x1 = this.x;\n",
    "        y = this.y;                       \n",
    "        K0 = sum(x1.^2,2)*ones(1,size(x1,1))+ones(size(x1,1),1)*sum(x1.^2,2)'-2*x1*x1';\n",
    "        OvPress = Inf;\n",
    "        bestSigma = 0;\n",
    "        bestMu  = 0;\n",
    "        for p in 1:length(Sig)   \n",
    "            lambda, V = eig(exp(-K0/(Sig[p]^2)));\n",
    "            Vt_y   = V'*y;\n",
    "            Vt_sqr = V'.^2;\n",
    "            xi     = sum(V,1)';        \n",
    "            xi2    = xi.^2;        \n",
    "            press = Inf;            \n",
    "            for i in 1:length(Mu)        \n",
    "                u     = xi./(lambda+Mu[i]);\n",
    "                g     = lambda./(lambda+Mu[i]);\n",
    "                sm    = -sum(xi2./(lambda+Mu[i]));                        \n",
    "                theta = Vt_y./(lambda+Mu[i])-(-sum(u.*Vt_y)/sm)*u;                                    \n",
    "                h     = Vt_sqr'*g + (V*(u.*lambda)-1).*(V*u)/sm;                    \n",
    "                f     = V*(lambda.*theta) + -sum(u.*Vt_y)/sm;\n",
    "                loo_resid = (y - f)./(1-h);             \n",
    "                tmp = sum(loo_resid.^2);    \n",
    "                if (tmp<press)\n",
    "                   press = tmp;\n",
    "                   mu    = Mu[i];\n",
    "                end                   \n",
    "            end\n",
    "            @printf(\"Sigma = %4.6f  mu = %4.6f   PRESS = %f\\n\",Sig[p], mu, press);\n",
    "            if (press<OvPress)\n",
    "                OvPress = press;\n",
    "                bestSigma = Sig[p];\n",
    "                bestMu    = mu;\n",
    "            end                \n",
    "        end    \n",
    "        @printf(\"\\nSigma = %f   mu = %f   PRESS = %f \\n\",bestSigma,bestMu,  OvPress);\n",
    "        _lsvm.setRBFWidth(bestSigma);\n",
    "        _lsvm.setRegParam(bestMu);\n",
    "        println(\"Trainin with best parameters\");\n",
    "        _lsvm.train(this.x, this.y);\n",
    "        return _lsvm;\n",
    "    end    \n",
    "    \n",
    "    this.evaluateKernel = \n",
    "    function(x1:: Array{Float64,},x2:: Array{Float64,}) \n",
    "        this.KernelType = uppercase(strip(this.KernelType));\n",
    "        if (this.KernelType==\"RBF\")\n",
    "            return this.evaluateRBF(x1,x2);\n",
    "        elseif     (this.KernelType==\"POLYNOMIAL\")\n",
    "            return   (x2*x1' + this.pol_ofset).^this.pol_order;\n",
    "        else \n",
    "            return x2*x1';\n",
    "        end\n",
    "    end          \n",
    "   \n",
    "   this.test = \n",
    "   function(xTest:: Array{Float64,})\n",
    "        return this.evaluateKernel(this.x,xTest)*this.alpha + this.bias\n",
    "   end     \n",
    "   \n",
    "   this.residuals =\n",
    "   function()\n",
    "       yhat = this.test(this.x);     \n",
    "       return  this.y -yhat;\n",
    "   end       \n",
    "   \n",
    "   this.looResiduals =\n",
    "   function()\n",
    "        n = this.ntp;\n",
    "        K = this.evaluateKernel(this.x,this.x);           \n",
    "        H        = [K   ones(n,1); zeros(1,n+1)]*inv([K+this.mu*eye(n) ones(n,1); ones(1,n) 0]);\n",
    "        yhat     = H*[y;0];\n",
    "        return (y-yhat[1:n])./(1-diag(H)[1:n]);\n",
    "   end   \n",
    "   \n",
    "   this.press =\n",
    "   function()\n",
    "     r = this.looResiduals();\n",
    "     return dot(r,r);\n",
    "   end  \n",
    "    \n",
    "    this.cvError = \n",
    "    function(folds::Int )        \n",
    "        netCV = this.copy();\n",
    "        n   = net.ntp;\n",
    "        pat = randperm(n);\n",
    "        partition = [1:n]%folds;        ;\n",
    "        err = 0.;\n",
    "        for i=0:folds-1\n",
    "           \n",
    "           testIndex  = find(x->x==i,partition);\n",
    "           trainIndex = find(x->x!=i,partition);  \n",
    "           \n",
    "           xtrain = this.x[pat[trainIndex],:]; ytrain = this.y[pat[trainIndex]];\n",
    "           xtest  = this.x[pat[testIndex],:];  ytest  = this.y[pat[testIndex]]; \n",
    "            \n",
    "           netCV.train(xtrain,ytrain);\n",
    "           yhat = netCV.test(xtest);              \n",
    "           resid = yhat - ytest;              \n",
    "           err  += dot(resid,resid);\n",
    "        end   \n",
    "        \n",
    "        return err;         \n",
    "    end\n",
    "    \n",
    "    \n",
    "    this.setRegParam = \n",
    "    function(mu :: Float64)\n",
    "       this.mu = mu;\n",
    "    end   \n",
    "    \n",
    "    \n",
    "    this.setKernelType = \n",
    "    function(s::String)\n",
    "      A = strip(uppercase(s));\n",
    "      if ( A in (\"RBF\", \"LINEAR\", \"POLYNOMIAL\" ))\n",
    "         this.KernelType = A;\n",
    "      else     \n",
    "          println(\"Only RBF, LINEAR, POLYNOMIAL are allowed\");          \n",
    "      end\n",
    "    end \n",
    "\n",
    "    this.printKernelInfo =\n",
    "    function() \n",
    "        println(\"Kernel = \",this.KernelType);\n",
    "        if (this.KernelType==\"RBF\")\n",
    "            println(\" RBF Width : sigma = \", this.sigma);            \n",
    "        elseif     (this.KernelType==\"POLYNOMIAL\")\n",
    "            println(\" order : pol_order = \", this.pol_order);\n",
    "            println(\" ofset : pol_ofset = \", this.pol_ofset);            \n",
    "        else\n",
    "        end\n",
    "    end        \n",
    "    \n",
    "    this.setPolyParams =\n",
    "    function(order :: Float64, ofset::Float64 )\n",
    "      if (this.KernelType == \"POLYNOMIAL\")\n",
    "        this.pol_order = order;\n",
    "        this.pol_ofset = ofset ;\n",
    "      else\n",
    "        println(\"Wrong Kernel\");\n",
    "      end        \n",
    "    end         \n",
    "\n",
    "    this.setRBFWidth =\n",
    "    function(sigma::Float64) \n",
    "      if (this.KernelType == \"RBF\")\n",
    "        this.sigma = sigma;        \n",
    "      else\n",
    "        println(\"Wrong Kernel\");\n",
    "      end        \n",
    "    end    \n",
    "    \n",
    "    \n",
    "    # need some work... because we this.x is shallow copy of x (from the training).. Pb..\n",
    "    this.standarize=\n",
    "    function()\n",
    "      this.means = mean(this.x,1);\n",
    "      this.stds  = std(this.x,1);\n",
    "      for i=1:length(this.means)\n",
    "        this.x[:,i] = (this.x[:,i]-this.means[i])/this.stds[i]; \n",
    "      end\n",
    "      this.standarized = true;      \n",
    "      println(\"warning : data x has changed, it is standarized\");\n",
    "    end\n",
    "    \n",
    "    \n",
    "    this.R2 = \n",
    "    function()     \n",
    "      return 1-sum(this.residuals().^2)/sum((this.y- mean(this.y)).^2); \n",
    "    end \n",
    "    \n",
    "    \n",
    "    this.RMSE = \n",
    "    function()\n",
    "       return  sqrt(mean(this.residuals().^2));\n",
    "    end   \n",
    "    \n",
    "    \n",
    "   return this;\n",
    "   \n",
    "end \n",
    "\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.0:0.1:5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = -5:.1:5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
